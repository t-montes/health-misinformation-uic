{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from utils import Results\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "board = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "prices = {\n",
    "    \"gpt-4o\": {\"input\":2.5, \"output\":10},\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct-Turbo\": {\"input\":0.88, \"output\":0.88},\n",
    "    \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\": {\"input\":3.5, \"output\":3.5},\n",
    "    \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\": {\"input\":0.88, \"output\":0.88},\n",
    "    \"Qwen/QwQ-32B-Preview\": {\"input\":1.2, \"output\":1.2},\n",
    "}\n",
    "\n",
    "files = os.listdir('results')\n",
    "for fpath in files:\n",
    "    if not fpath.endswith('.csv'):\n",
    "        continue\n",
    "    dataset = fpath.split('-')[0]\n",
    "    ids = [\"article_id\"] if dataset == \"medmmhl\" else [\"article_id\",\"claim_id\"]\n",
    "    results = Results(\n",
    "        f\"./results/{fpath}\",\n",
    "        sep=';',\n",
    "        ids=ids\n",
    "    )\n",
    "    model = results.df.loc[0].model\n",
    "    macro = results.get_macro_score()\n",
    "    tokens = results.get_tokens()\n",
    "    cost = round((tokens[\"input\"] * prices[model][\"input\"] + tokens[\"output\"] * prices[model][\"output\"])/1e6, 2)\n",
    "    for target in macro:\n",
    "        macro[target][\"cost\"] = float(cost)\n",
    "        macro[target][\"# executions\"] = len(results.df)\n",
    "        board[dataset][target][model] = macro[target]\n",
    "\n",
    "    # save results.df in a ./results/excel folder\n",
    "    #results.df.to_excel(f\"./results/excel/{fpath.replace('csv','xlsx')}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table: medmmhl-stance\n",
      "                                        Model  precision  recall  f1-score  accuracy  cost  # executions\n",
      "                                       gpt-4o       0.84    0.80      0.78      0.79  4.71          2000\n",
      "      meta-llama/Llama-3.3-70B-Instruct-Turbo       0.82    0.76      0.74      0.75  1.11          2000\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo       0.24    0.22      0.21      0.75  4.48          2000\n",
      "    nvidia/Llama-3.1-Nemotron-70B-Instruct-HF       0.11    0.10      0.10      0.71  1.21          2000\n",
      "                         Qwen/QwQ-32B-Preview       0.24    0.22      0.22      0.78  0.65           678\n",
      "\n",
      "Table: monant-presence\n",
      "                                        Model  precision  recall  f1-score  accuracy  cost  # executions\n",
      "                                       gpt-4o       0.55    0.64      0.52      0.66  2.65           500\n",
      "      meta-llama/Llama-3.3-70B-Instruct-Turbo       0.55    0.64      0.49      0.61  0.82           500\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo       0.54    0.63      0.49      0.61  3.30           500\n",
      "    nvidia/Llama-3.1-Nemotron-70B-Instruct-HF       0.38    0.45      0.35      0.67  0.83           500\n",
      "                         Qwen/QwQ-32B-Preview       0.26    0.28      0.18      0.39  1.50           500\n",
      "\n",
      "Table: monant-stance\n",
      "                                        Model  precision  recall  f1-score  accuracy  cost  # executions\n",
      "                                       gpt-4o       0.31    0.25      0.19      0.23  2.65           500\n",
      "      meta-llama/Llama-3.3-70B-Instruct-Turbo       0.33    0.28      0.20      0.23  0.82           500\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo       0.33    0.31      0.23      0.27  3.30           500\n",
      "    nvidia/Llama-3.1-Nemotron-70B-Instruct-HF       0.26    0.21      0.15      0.22  0.83           500\n",
      "                         Qwen/QwQ-32B-Preview       0.20    0.20      0.13      0.26  1.50           500\n"
     ]
    }
   ],
   "source": [
    "for category, subcategories in board.items():\n",
    "    for subcategory, models in subcategories.items():\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame.from_dict(models, orient='index')\n",
    "        df.index.name = 'Model'\n",
    "        df.reset_index(inplace=True)\n",
    "        print(f\"\\nTable: {category}-{subcategory}\")\n",
    "        print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
